# Installation puis importation des packages 
# Packages de manipulation de donn√©es
import pandas as pd
import pickle as pk
import joblib

# Packages de visualisation de donn√©es 
import seaborn as sns
import matplotlib.pyplot as plt # √† remplacer par plotly express
import plotly.express as px

# Packages de machine learning
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler, StandardScaler
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, classification_report, confusion_matrix

# Package l'interface web
import streamlit as st

# PARTIE 1 : CHARGEMENT DE TOUTES LES FONCTIONS ET VARIABLES UTILES POUR LE PROCESSUS
# Chargement des fichiers
# Chemin vers les fichiers contenant les donn√©es d'entrainement, de test et de leur description
fichier_train = 'churn_data_train.txt'
fichier_test = 'churn_data_test.txt'
description = 'description.txt'

# Lecture les ensembles de donn√©es
# Je dois utiliser l'option 'sep' pour sp√©cifier √† pandas que les donn√©es sont s√©par√©es par 1 espace.
df_train = pd.read_csv(fichier_train, sep=r" ", engine='python')
df_test = pd.read_csv(fichier_test, sep=r" ", engine='python')

# Description des donn√©es dans chaque colonne
def description_donnees(description):
    with open(description, 'r', encoding='utf-8') as file:
        description = file.read()
    return description

# Toute bonne analyse commence par de l'observation.
def echantillon(df):
    df_echantillon = df.sample(3)
    return df_echantillon

# Dimensions du dataset
def dimension(df):
    return {df.shape[0]}, {df.shape[1]}

nb_lignes, nb_colonnes = dimension(df_train)

# Ordonner les index des donn√©es
def ordonne_index(df):
    df_ordonne = df.sort_index()
    return df_ordonne

# Identifier les colonnes num√©riques et celles cat√©gorielles dans les deux ensembles de donn√©es.
col_numeriques = df_test.select_dtypes(include=["float64", "int64"]).columns
col_categorielles = df_test.select_dtypes(include=["object"]).columns

# **3. Analyse des anomalies et donn√©es manquantes**
# V√©rificattion des valeurs manquantes dans les donn√©es
def donnees_manquantes(df):
    donnees_manquantes = df.isnull().sum()
    donnees_manquantes = donnees_manquantes[donnees_manquantes > 0].sort_values(ascending=False)
    st.write("\nLes colonnes avec le nombre de valeurs manquantes :")
    st.write(donnees_manquantes)


# Valeurs aberrantes dans les colonnes num√©riques de mes donn√©es
# Initialiser une liste pour stocker les colonnes avec valeurs aberrantes
colonnes_aberrantes = []

def valeurs_aberrantes(df, col_numeriques):
    # D√©finir le seuil pour identifier les valeurs aberrantes en fonction du score Z
    seuil_z = 3

    # Boucle √† travers chaque colonne num√©rique
    for colonne in col_numeriques:
        # Calculer la moyenne et l'√©cart-type de la colonne actuelle
        moyenne = df[colonne].mean()
        ecart_type = df[colonne].std()

        # Calculer les scores Z pour la colonne actuelle
        scores_z = (df[colonne] - moyenne) / ecart_type

        # Identifier les valeurs aberrantes pour la colonne actuelle
        valeurs_aberrantes = df[abs(scores_z) > seuil_z]

        # Afficher les valeurs aberrantes pour la colonne actuelle
        if not valeurs_aberrantes.empty:
             colonnes_aberrantes.append(colonne)
             #print(f"Voici les valeurs aberrantes dans la colonne '{colonne}' avec zscore = 3 :")
             #for index, valeur in valeurs_aberrantes[colonne].items():
                #print(f"Ligne: {index}, Valeur: {valeur}")
    st.write(f"\nIl y a {len(colonnes_aberrantes)} colonnes avec des valeurs aberrantes : {colonnes_aberrantes}")


# V√©rification s'il y a des lignes dupliqu√©es
def lignes_dupliquees(df):
    lignes_dupliquees = df[df.duplicated()]
    st.write(f"Il y a {lignes_dupliquees.shape[0]} lignes dupliqu√©es dans cet ensemble de donn√©es.")

# Colonnes cat√©gorielles avec le nombre de valeurs uniques
def count_unique_values(df):
    # Cr√©er un dictionnaire pour stocker les r√©sultats
    unique_counts_dict = {}
    # Compter les valeurs uniques pour chaque colonne cat√©gorielle
    for col in col_categorielles:
        unique_counts_dict[col] = df[col].nunique()
    # Convertir le dictionnaire en DataFrame et d√©finir l'index
    unique_counts = pd.DataFrame.from_dict(unique_counts_dict, orient='index', columns=['Nombre Valeurs distinctes'])
    return unique_counts

def valeurs_uniques(df, col_categorielles):
    for col in col_categorielles:
        col_value_unique = df[col].unique()
        st.write(f"Il y a {len(col_value_unique)} valeurs uniques dans la colonne '{col}':\n{df[col].value_counts()}\n")

# **1. Transformation des valeurs manquantes**
# Remplacement des valeurs manquantes dans chaque colonne
def valeur_manquante_remplacee(df, col, valeur):
    df[col].fillna({col : valeur}, inplace=True)
    #st.write(f"\nLes valeurs manquantes dans '{col}' sont remplac√©es par {valeur}.")

# Remplacement des valeurs atypiques '-99' de la colonne 'Customer.Satisfaction' par la valeur 's0'
def remplacement_valeur_atypique(df, col, valeur_actuelle, valeur_future):
    df[col] = df[col].replace(valeur_actuelle, valeur_future)
    st.write(f"\nLes valeurs atypiques '{valeur_actuelle}' dans '{col}' sont remplac√©es par '{valeur_future}'.")


# S√©lection des colonnes cat√©gorielles avec 2 valeurs uniques avec une boucle for           
col_cat_deux_valeurs = []
col_cat_plus_deux_valeurs = []

def repartition_valeurs_uniques(df, col_categorielles):

    for col in col_categorielles:
        if df[col].nunique() == 2:
            col_cat_deux_valeurs.append(col)
            #st.write(f"\nLa colonne '{col}' a {df[col].nunique()} valeurs uniques et est ajout√©e √† 'col_cat_deux_valeurs'.")
        else:
            col_cat_plus_deux_valeurs.append(col)
            #st.write(f"\nLa colonne '{col}' a {df[col].nunique()} valeurs uniques et est ajout√©e √† 'col_cat_plus_deux_valeurs'.")

# Encodage de la colonne avec labelEncoder s'il est dans col_cat_deux_valeurs          
def encodage_deux_valeurs(df, col_cat_deux_valeurs):
    for col in col_cat_deux_valeurs:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        #st.write(f"La colonne '{col}' a √©t√© encod√©e avec LabelEncoder.")

# Normalisation des colonnes avec des outliers avec RobustScaler
def normalisation_outliers(df):
    robust_scaler = RobustScaler()
    df[colonnes_aberrantes] = robust_scaler.fit_transform(df[colonnes_aberrantes])

# Normalisation des colonnes sans outliers avec standardScaler
colonnes_non_aberrantes = [col for col in col_numeriques if col not in colonnes_aberrantes]
# Supprimer les colonnes 'Churn.Value', 'Longitude', 'Latitude' des colonnes non aberrantes
for col in ['Churn.Value', 'Longitude', 'Latitude']:
    if col in colonnes_non_aberrantes:
        colonnes_non_aberrantes.remove(col)

def normalisation_non_outliers(df):
    standard_scaler = StandardScaler()
    df[colonnes_non_aberrantes] = standard_scaler.fit_transform(df[colonnes_non_aberrantes])

# chargement des donn√©es d'entrainement pretrait√©es apr√®s avoir transform√© les donn√©es
df_train_copy = pk.load(open("df_train_traitees.pkl", "rb"))
df_test_copy = pk.load(open("df_test_traitees.pkl", "rb"))

# **5. Selections des caract√©ristiques importantes**
# üéØ Objectif : Pr√©parer les donn√©es train pour entra√Æner et √©valuer le mod√®le.
def selection_colonnes_train(df, colonnes_selectionnees):
    X_train = df[colonnes_selectionnees]
    y_train = df["Churn.Value"]
    return X_train, y_train

# Pr√©parer les donn√©es test pour tester le mod√®le
def selection_colonnes_test(df, colonnes_selectionnees):
    X_test = df[colonnes_selectionnees]
    y_test = df["Churn.Value"]
    return X_test, y_test

# Fonction pour charger le mod√®le avec mise en cache
@st.cache_resource
def load_model():
    return joblib.load("xgboost_model.joblib")


# PARTIE 2 : CREATION DES PAGES ET UTILISATION DES FONCTIONS ET VARIABLES
# Page: Accueil
def page_accueil():
    st.title("Accueil")
    st.write("### Bienvenue sur l'application de pr√©diction du d√©sabonnement")
    st.write("L'objectif de ce travail est de pr√©dire le d√©sabonnement des clients dans l'industrie des t√©l√©communications.")
    st.image("prediction.png", caption="Image g√©n√©r√©e avec Microsoft designer pour illustrer le d√©sabonnement en t√©l√©com")
    st.write("Dans le secteur des t√©l√©communications, les clients peuvent choisir entre plusieurs fournisseurs de services et passer activement de l'un √† l'autre.")
    st.error("Probl√®me dans la t√©l√©com:")
    st.write("La fid√©lisation individualis√©e des clients est difficile car la plupart des entreprises ont un grand nombre de clients et ne peuvent pas se permettre de consacrer beaucoup de temps √† chacun d'entre eux. Les co√ªts seraient trop √©lev√©s et l'emporteraient sur les recettes suppl√©mentaires.")
    st.info("Rappel important :")
    st.write("Si une entreprise pouvait pr√©voir √† l'avance quels clients sont susceptibles de la quitter, elle pourrait concentrer ses efforts de fid√©lisation uniquement sur ces clients ¬´ √† haut risque ¬ª.")
    st.write("En s'attaquant au probl√®me du d√©sabonnement, les entreprises de t√©l√©com peuvent non seulement pr√©server leur position sur le march√©, mais aussi se d√©velopper et prosp√©rer. Plus il y a de clients dans leur r√©seau, plus le co√ªt d'initiation est faible et plus les b√©n√©fices sont importants. Par cons√©quent, l'objectif principal de l'entreprise pour r√©ussir est de r√©duire l'attrition des clients et de mettre en ≈ìuvre une strat√©gie de fid√©lisation efficace.")
    st.success("Approche de solution :")
    st.write("Pour d√©tecter les signes pr√©curseurs d'un d√©sabonnement potentiel, il faut d'abord d√©velopper une vision globale des clients et de leurs interactions sur de nombreux canaux, notamment l'utilisation du service, l'historique des probl√®mes rencontr√©s, les appels au service client√®le, pour n'en citer que ces quelques-uns.")
    st.write("Rendez-vous sur la page Informations pour en savoir plus sur les donn√©es collect√©es sur les clients")

# Page: Informations
def page_informations():
    st.title("Informations")
    st.write("### Informations sur les donn√©es")
    st.write("Cette page fournit des d√©tails sur les sources, formats et descriptions des donn√©es utilis√©es.")
    st.info("LES DONNEES (REELLES OU FICTIVES) UTILISEES DANS CE PROJET SONT FOURNIES POUR EFFECTUER UN TEST")
    st.info("Aper√ßu d'un √©chantillon des donn√©es d'entrainement du mod√®le (df_train)")
    st.write(echantillon(df_train))
    st.info("Aper√ßu d'un √©chantillon des donn√©es pour tester le mod√®le (df_test)")
    st.write(echantillon(df_test))
    st.write("Voici une description d√©taill√©e et compr√©hensible de chacune des colonnes de mes deux ensembles de donn√©es, ainsi que leurs significations : ")
    st.write(description_donnees(description))

    st.info("Passons √† l'exploration de ces donn√©es")
  

# Page: Exploration des donn√©es
def page_exploration_des_donnees():
    st.title("Exploration des donn√©es")
    st.write("### **1. Compr√©hension de la structure des donn√©es**")
    st.write("Dimensions des ensembles de donn√©es")
    st.write("Donn√©es d'entrainement : il y a", nb_lignes, "lignes et ", nb_colonnes, "colonnes dans chaque ensemble de donn√©es")
    st.success("Trie des index et affichage de chaque ensemble de donn√©es")
    st.write("Donn√©es d'entrainement :\n", ordonne_index(df_train))
    st.write("Donn√©es de test :\n", ordonne_index(df_test))
    st.info("\nIdentification des colonnes num√©riques et celles cat√©gorielles\n")
    st.write(f"Nous avons {len(list(col_numeriques))} colonnes num√©riques : {list(col_numeriques)}")
    st.write(f"\nNous avons {len(list(col_categorielles))} colonnes cat√©gorielles : {list(col_categorielles)}")
    st.write("### **2. Satistiques descriptives**")
    st.write("Satistiques descriptives des colonnes num√©riques :")
    statistique_descriptive_col_numeriques = df_train[col_numeriques].describe()
    st.write(statistique_descriptive_col_numeriques.T)
    st.write("Satistiques descriptives des colonnes categorielles :")
    statistique_descriptive_col_categorielles = df_train[col_categorielles].describe()
    st.write(statistique_descriptive_col_categorielles.T)
    st.write("### **3. Analyse des anomalies et donn√©es manquantes dans train et test**")
    st.write("V√©rificattion des valeurs manquantes dans chaque colonne de mes donn√©es")
    st.write("Donn√©es manquantes dans le train :\n", )
    donnees_manquantes(df_train)
    st.write("Donn√©es manquantes dans le test :\n", )
    donnees_manquantes(df_test)
    st.warning("Valeurs aberrantes identifi√©es dans les donn√©es train √† l'aide de z-score")
    valeurs_aberrantes(df_train, col_numeriques)
    st.warning("Valeurs aberrantes identifi√©es dans les donn√©es test √† l'aide de z-score")
    valeurs_aberrantes(df_test, col_numeriques)
    st.error("V√©rification s'il y a des lignes dupliqu√©es dans le train :")
    lignes_dupliquees(df_train)
    st.error("V√©rification s'il y a des lignes dupliqu√©es dans le test :")
    lignes_dupliquees(df_test)
    st.info("Colonnes cat√©gorielles avec le nombre de valeurs uniques dans train :")
    count_unique_values(df_train).T
    st.info("Colonnes cat√©gorielles avec le nombre de valeurs uniques dans test :")
    count_unique_values(df_test).T
    st.write("Colonnes cat√©gorielles avec le nombre de valeurs uniques dans l'ensemble de donn√©es")
    if st.checkbox("Afficher le nombre d'occurence de valeurs distinctes par colonne de donn√©es train"):
        valeurs_uniques(df_train, col_categorielles)
        st.write("Remarque : La valeur '-99' la plus fr√©quente de la colonne 'Customer.Satisfaction' n'est pas une cha√Æne de caract√®res semblable aux autres de la m√™me colonne. Nous allons g√©rer son cas par la suite.")
    if st.checkbox("Afficher le nombre d'occurence de valeurs distinctes par colonne de donn√©es test"):
        valeurs_uniques(df_test, col_categorielles)
        st.write("Remarque : La valeur '-99' la plus fr√©quente de la colonne 'Customer.Satisfaction' n'est pas une cha√Æne de caract√®res semblable aux autres de la m√™me colonne. Nous allons g√©rer son cas par la suite.")
        st.write("Rendez-vous sur la page transformation pour comprendre les modifications apport√©es aux donn√©es collect√©es")

# Page: Transformation des donn√©es
def page_transformation_des_donnees():
    st.title("Ing√©nieurie de fonctionnalit√©s")
    st.write("### **1. Transformation des donn√©es manquantes et atypiques**")
    st.warning("Remplacement des valeurs manquantes dans chaque colonne des donn√©es train et test")
    valeur_manquante_remplacee(df_train, 'Offer', 'No Offer') # train
    valeur_manquante_remplacee(df_test, 'Offer', 'No Offer') # test
    st.success("Dans les deux ensembles de donn√©es, les donn√©es manquantes dans 'Offer' sont remplac√©es par 'No Offer', pas d'offre")
    valeur_manquante_remplacee(df_train, 'Internet.Type', 'Mobile Networks') # train
    valeur_manquante_remplacee(df_test, 'Internet.Type', 'Mobile Networks') # test
    st.success("Dans les deux ensembles de donn√©es, les donn√©es manquantes dans 'Internet.Type' sont remplac√©es par 'Mobile Networks', R√©seau Mobile")
    st.write("Remplacement des valeurs atypiques dans les deux ensembles de donn√©es")
    remplacement_valeur_atypique(df_train, 'Customer.Satisfaction', '-99', 's0') # train
    remplacement_valeur_atypique(df_test, 'Customer.Satisfaction', '-99', 's0')  # test
    st.success("Les valeurs atypiques '-99' de la colonne 'Customer.Satisfaction' dans les deux ensembles de donn√©es sont remplac√©es par's0'")
    st.write("### **2. Encodage des donn√©es**")
    st.info("Pour √©viter de cr√©er une relation d'ordre trompeur dans nos donn√©es :")
    st.write("**Encodons les colonnes avec deux valeurs uniques avec le labelEncoder**")
    repartition_valeurs_uniques(df_train, col_categorielles)
    # Cr√©ation d'une copie des donn√©es
    df_train_copy = df_train.copy()  
    df_test_copy = df_test.copy()
    encodage_deux_valeurs(df_train_copy, col_cat_deux_valeurs) # train      
    encodage_deux_valeurs(df_test_copy, col_cat_deux_valeurs) # test
    st.success("Les colonnes avec deux valeurs uniques ont √©t√© encod√© avec labelEncoder")
    st.write("**Encodons les colonnes avec plus de deux valeurs uniques avec le One Hot Encoder**")
    df_train_copy = pd.get_dummies(df_train_copy, columns=col_cat_plus_deux_valeurs, dtype=int)
    df_test_copy = pd.get_dummies(df_test_copy, columns=col_cat_plus_deux_valeurs, dtype=int)
    st.success("Les colonnes avec plus de deux valeurs uniques ont √©t√© encod√© avec One Hot Encoder")
    st.write("### **3. Normalisation des colonnes num√©riques**")
    st.write("Normalisation des valeurs des colonnes identifi√©es comme des outliers avec RobustScaler")
    st.write("Rappel, dans le train :")
    valeurs_aberrantes(df_train_copy, col_numeriques)
    st.write("Rappel, dans le test :")
    valeurs_aberrantes(df_test_copy, col_numeriques)
    normalisation_outliers(df_train_copy) # train
    normalisation_outliers(df_test_copy) # test
    st.success("Les valeurs des colonnes identifi√©es comme des outliers sont normalis√©es avec RobustScaler")
    st.write("Normalisation des valeurs des colonnes identifi√©es comme non outliers avec StandardScaler")
    normalisation_non_outliers(df_train_copy) # train
    normalisation_non_outliers(df_test_copy) # test
    st.success("Les valeurs des colonnes identifi√©es comme non outliers sont normalis√©es avec StandardScaler")
    # Enregistrer les donn√©es pr√©trait√©es
    df_train_copy.to_pickle("df_train_traitees.pkl")
    st.info("9. Les donn√©es d'entrainement pr√©trait√©es sont enregistr√©es dans **df_train_traitees** au format pickle afin de l'utiliser par la suite")
    df_test_copy.to_pickle("df_test_traitees.pkl")
    st.info("9. Les donn√©es de test pr√©trait√©es sont enregistr√©es dans **df_test_traitees** au format pickle afin de l'utiliser par la suite")
 
# Page: Visualisation des donn√©es
def page_visualisation_des_donnees():
    st.title("Visualisation des donn√©es")
    st.write("### **1. Visualisation des donn√©es d'entrainement identifi√©es comme anormales**")
    valeurs_aberrantes(df_train, col_numeriques)
    st.write("### **2. Regardons les correlations dans les donn√©es train**")
    # Matrice de correlation
    corr = df_train_copy.corr()
    # Trier les corr√©lations par ordre croissant
    corr_triee = corr['Churn.Value'].sort_values(ascending=True)
    # S√©lectionner les colonnes dans l'ordre tri√©
    colonnes_triees = corr_triee.index.tolist()
    #st.pyplot.figure(figsize=(20, 15))
    # Cr√©er le heatmap avec les colonnes tri√©es
    # Cr√©er une figure pour le heatmap
    fig, ax = plt.subplots(figsize=(10, 8))  # Taille ajust√©e pour une meilleure lisibilit√©
    # Cr√©er le heatmap avec Seaborn
    sns.heatmap(
        corr.loc[colonnes_triees, ['Churn.Value']],
        annot=True,
        cmap='YlGnBu',
        ax=ax,
        cbar_kws={'label': 'Correlation'})

    # Ajouter un titre au heatmap
    ax.set_title('Heatmap des corr√©lations tri√©es avec Churn.Value', fontsize=16)

    # Afficher le graphique dans Streamlit
    st.pyplot(fig)

# Page: D√©veloppement de mod√®les
def page_developpement_de_modeles():
    st.title("D√©veloppement de mod√®les")
    st.write("### **D√©veloppement du Mod√®le**")
    st.write("**S√©lection des caract√©ristiques importantes selon le coefficient de corelation**")
    corr = df_train_copy.corr()
    # Cr√©ation d'une liste vide pour stocker les colonnes s√©lectionn√©es pour entrainer le mod√®le
    colonnes_selectionnees = []
    # Seuil de corr√©lation : les colonnes autour de 0 (-0.03 √† 0.03) ne seront pas s√©lectionn√©es
    st.write("Seules les colonnes dont le **coefficient** est autour de **0** (-0.03 √† 0.03) ne seront pas s√©lectionn√©es")
    seuil = 0.03
    for index, row in corr[['Churn.Value']].iterrows():
        if abs(row['Churn.Value']) > seuil:
            colonnes_selectionnees.append(index)
    st.write("Voici les", len(colonnes_selectionnees), "colonnes importantes pour notre mod√®le :", colonnes_selectionnees)   
    # Repartition des donn√©es de train et celles de test
    X_train, y_train = selection_colonnes_train(df_train_copy, colonnes_selectionnees)
    X_test, y_test = selection_colonnes_test(df_test_copy, colonnes_selectionnees)
    st.info("### **Derni√®res v√©rifications**")
    st.write("**Voici un aper√ßu des donn√©es finales trait√©es pour l'entra√Ænement du mod√®le :**")  
    st.write("Voici les catact√©ristiques :\n", X_train.head())
    st.write("Voici les exemples de la valeur cible :\n", y_train.head())
    st.write("**Voici un aper√ßu des donn√©es nouvelles trait√©es pour tester mod√®le :**")
    st.write("Voici les catact√©ristiques :\n", X_test.head())
    st.write("Voici la cible √† pr√©sire :\n", y_test.head())
    st.success("Voici un aper√ßu de la compl√©mentarit√© entre les donn√©es d'entrainement et celles de test : Explorez les indices de lignes des donn√©es du premier tableau et celui du deuxi√®me √©galement.")
    st.write(ordonne_index(X_train))
    st.write(ordonne_index(X_test))
    st.write("### Choix du mod√®le final pour la pr√©diction : xgboost")
    st.write("L'algorithme XGBoost id√©al dans le domaine des t√©l√©communications car : \n - Il g√®re parfaitement les donn√©es d√©s√©quilibr√©es. \n - Il est efficace sur les donn√©es manquantes oes services moins utilis√©s. \n - Il traite rapidement les grands volumes de donn√©es en capturant des relations complexes.")
    # Utilisation d'une validation crois√©e √† 5 plis pour mieux g√©n√©raliser les performances.
    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    # Mod√®le XGBoost
    model_xgb = xgb.XGBClassifier(
        objective="binary:logistic",  # Pour un probl√®me de classification binaire
        n_estimators=100,            # Nombre d'arbres
        max_depth=6,                 # Profondeur des arbres
        learning_rate=0.1,           # Taux d'apprentissage
        random_state=42              # Pour la reproductibilit√©
        )
    # Entrainement du mod√®le
    model_xgb.fit(X_train, y_train)
    st.success("Le mod√®le XGBoost a √©t√© entrain√© avec success")
    # Optimisation des hyperparam√®tres**
    st.write("**Utilisation de GridSearch pour trouver la meilleure combinaison de param√®tres.**")
    param_grid = {
        'n_estimators': [50, 100, 200],
        'max_depth': [3, 6, 10],
        'learning_rate': [0.01, 0.1, 0.2],
        'subsample': [0.8, 1.0]
        }

    grid_search = GridSearchCV(
        estimator=xgb.XGBClassifier(objective="binary:logistic", random_state=42),
        param_grid=param_grid,
        cv=3,
        scoring='accuracy'
        )

    grid_search.fit(X_train, y_train)
    st.write("Voici la combinaison optimale des param√®tres (meilleurs param√®tres) obtenus avec GridSearch :", grid_search.best_params_)

    st.info("**R√©entra√Ænement du mod√®le avec les meilleurs param√®tres**")
    best_model = grid_search.best_estimator_
    best_model.fit(X_train, y_train)
    joblib.dump(best_model, "xgboost_model.joblib")
    st.success("Le mod√®le a √©t√© bien r√©entra√Æn√© et sauvegard√© dans le fichier 'modele_xgboost.joblib")

# Page: Faire des Pr√©dictions
def page_faire_des_predictions():
    st.title("Faire des Pr√©dictions")
    st.write("### Pr√©dictions sur de nouvelles donn√©es en temps r√©el")
    st.write("Testez le mod√®le avec de nouvelles donn√©es fournies par le fichier test.")
    # Chargement du mod√®le pr√©entrain√© fichier joblib du mod√®le
    xgboost_model = load_model()
    st.success("**Le mod√®le est pr√®t pour faire des pr√©dictions**")
    # Cr√©ation d'une liste vide pour stocker les colonnes s√©lectionn√©es pour tester le mod√®le
    corr = df_train_copy.corr()
    colonnes_selectionnees = []
    # Seuil de corr√©lation : les colonnes autour de 0 (-0.03 √† 0.03) ne seront pas s√©lectionn√©es
    seuil = 0.03
    for index, row in corr[['Churn.Value']].iterrows():
        if abs(row['Churn.Value']) > seuil:
            colonnes_selectionnees.append(index)
    X_test, y_test = selection_colonnes_test(df_test_copy, colonnes_selectionnees)
    # Faire des pr√©dictions sur les donn√©es test
    if st.button("Pr√©dire"):
        y_pred = xgboost_model.predict(X_test) # Pr√©dictions des classes
        y_pred_prob = xgboost_model.predict_proba(X_test)  # Probabilit√© associ√©e √† la pr√©diction de la classe
        # Combiner les r√©sultats dans un DataFrame pour une meilleure lisibilit√©
        # R√©cup√©rer et ajouter l'index de df1 dans df2
        customerID = y_test.index.to_series().reset_index(drop=True)
        resultats = pd.DataFrame({
            "customerID": customerID,  # Index de la ligne
            #"Probabilite_Classe_0": y_pred_prob[:, 0],  # Probabilit√© pour la classe 0
            "churn probability": y_pred_prob[:, 1],   # Probabilit√© pour la classe 1
            "churn value": y_pred
            })
        resultats = resultats.set_index("customerID")
        st.write(f"Voici le r√©sultat des {len(y_pred)} pr√©dictions sur les donn√©es test avec la valeur de la probabilit√© par classe 1: \n", resultats)
        
        st.info("### **Evaluation du mod√®le**")
        st.write("**Les m√©trics suivants sont utilis√©s pour √©valuer les performances du mod√®le**")
        st.info("""A savoir : **VP** : Vrais positifs (correctement pr√©dits comme positifs). \n **VN** : Vrais n√©gatifs (correctement pr√©dits comme n√©gatifs).
                   **FP** : Faux positifs (pr√©dits positifs √† tort). \n **FN** : Faux n√©gatifs (rat√©s comme positifs).""")
        st.write(" - **Pr√©cision** = Parmi les positifs pr√©dits, combien sont corrects ? \n _Focus sur la qualit√© des pr√©dictions positives._")
        st.write(" - **Rappel** = Parmi les positifs r√©els, combien sont d√©tect√©s ? \n _Focus sur la capacit√© de capturer les vrais positifs._")
        st.write(" - **Score F1** = Trouvons un √©quilibre entre pr√©cision et rappel. \n _Quand ni FP ni FN ne doivent dominer._")
        st.write(" - **Matrice de confusion** = O√π est-ce que mon mod√®le se trompe ? \n _Un tableau clair pour d√©composer les erreurs._")
        st.write(f"Pr√©cision du mod√®le :\n {accuracy_score(y_test, y_pred)}")
        st.write(f"Rappel du mod√®le :\n {recall_score(y_test, y_pred)}")
        st.write(f"Score F1 du mod√®le :\n {f1_score(y_test, y_pred)}")
        st.write(f"Matrice de confusion du mod√®le :")
        st.write(confusion_matrix(y_test, y_pred))
        st.success("Le mod√®le affiche une performance extr√™me (100 pour 100) de taux de r√©ussite pour toutes les m√©triques sur les donn√©es nouvelles pr√©dites.") 
        

# Page: Documentation du projet
def page_documentation_du_projet():
    st.title("Documentation du projet")
    st.write("### Guide de l'utilisateur")
    st.info("Pour un projet en production, le guide devrait √™tre ajout√©")
    

# Main app
def main():
    st.set_page_config(page_title="Pr√©sentation du projet", layout="wide")

    # Sidebar navigation
    page = st.sidebar.radio("Navigation", [
        "Accueil", 
        "Informations", 
        "Exploration des donn√©es", 
        "Ing√©nieurie de fonctionnalit√©s", 
        "Visualisation des donn√©es", 
        "D√©veloppement de mod√®les", 
        "Faire des Pr√©dictions", 
        "Documentation du projet"
    ])

    # Display the selected page
    if page == "Accueil":
        page_accueil()
    elif page == "Informations":
        page_informations()
    elif page == "Exploration des donn√©es":
        page_exploration_des_donnees()
    elif page == "Ing√©nieurie de fonctionnalit√©s":
        page_transformation_des_donnees()
    elif page == "Visualisation des donn√©es":
        page_visualisation_des_donnees()
    elif page == "D√©veloppement de mod√®les":
        page_developpement_de_modeles()
    elif page == "Faire des Pr√©dictions":
        page_faire_des_predictions()
    elif page == "Documentation du projet":
        page_documentation_du_projet()

if __name__ == "__main__":
    main()
